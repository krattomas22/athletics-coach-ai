import os, io, zipfile, json, hashlib
from datetime import date
from typing import List, Dict, Any

import streamlit as st
import requests
from pypdf import PdfReader
from PIL import Image
import pytesseract

# --- Embeddings & Vector DB ---
import faiss
from sentence_transformers import SentenceTransformer

# --- LLM (OpenAI jako pÅ™Ã­klad, mÅ¯Å¾eÅ¡ vymÄ›nit) ---
from openai import OpenAI

# ========== KONFIG ==========
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "PASTE_YOUR_KEY")  # nastav ve Streamlit Secrets pro sdÃ­lenÃ­

DEFAULT_CITY = "ÄŒeskÃ© BudÄ›jovice"
MODEL_EMB = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"  # Äesky OK
MODEL_CHAT = "gpt-4o-mini"  # libovolnÃ½ kompatibilnÃ­ model

APP_TITLE = "TrÃ©ninkovÃ½ plÃ¡novaÄ"
ASSETS_DIR = os.path.join(os.path.dirname(__file__), "assets")  # sem dej svÃ¡ PDF/ZIP se zdroji

# ========== UI HLAVIÄŒKA ==========
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸƒ", layout="wide")
st.title(APP_TITLE)

# ========== STAV A POMOCNÃ‰ ==========
if "docs" not in st.session_state:
    st.session_state.docs = []  # list[dict]: {id, text, meta}
if "index" not in st.session_state:
    st.session_state.index = None
if "emb_model" not in st.session_state:
    st.session_state.emb_model = None  # lazy-load
if "openai_client" not in st.session_state:
    st.session_state.openai_client = OpenAI(api_key=OPENAI_API_KEY)
if "assets_loaded" not in st.session_state:
    st.session_state.assets_loaded = False

def hash_text(t: str) -> str:
    return hashlib.sha1(t.encode("utf-8")).hexdigest()[:10]

def clean_text(t: str) -> str:
    return " ".join(t.replace("\n", " ").split())

def chunk_text(text: str, chunk_size: int = 800, overlap: int = 100) -> List[str]:
    words = text.split()
    chunks = []
    i = 0
    while i < len(words):
        chunk = words[i:i+chunk_size]
        chunks.append(" ".join(chunk))
        i += (chunk_size - overlap)
    return chunks

def embed_texts(texts: List[str]):
    if st.session_state.emb_model is None:
        with st.spinner("NaÄÃ­tÃ¡m embedding modelâ€¦"):
            st.session_state.emb_model = SentenceTransformer(MODEL_EMB)
    return st.session_state.emb_model.encode(texts, show_progress_bar=False, convert_to_numpy=True)

def ensure_faiss(index_dim: int):
    if st.session_state.index is None:
        st.session_state.index = faiss.IndexFlatIP(index_dim)

def add_to_corpus(text: str, source: str, page: int | None = None):
    text = clean_text(text)
    if not text.strip():
        return []
    chunks = chunk_text(text)
    for j, ch in enumerate(chunks):
        meta = {"source": source, "page": page, "chunk_id": j, "id": hash_text(f"{source}-{page}-{j}")}
        st.session_state.docs.append({"id": meta["id"], "text": ch, "meta": meta})

def build_or_update_index():
    texts = [d["text"] for d in st.session_state.docs]
    if not texts:
        return
    vecs = embed_texts(texts)
    ensure_faiss(vecs.shape[1])
    st.session_state.index.reset()
    st.session_state.index.add(vecs)

def search_similar(query: str, k: int = 5) -> List[Dict[str, Any]]:
    if st.session_state.index is None or len(st.session_state.docs) == 0:
        return []
    qv = embed_texts([query])
    D, I = st.session_state.index.search(qv, k)
    out = []
    for idx in I[0]:
        if idx == -1:
            continue
        out.append(st.session_state.docs[idx])
    return out

# ========== INGEST: PDF / ZIP z assets ==========
def is_image_name(n: str) -> bool:
    n = n.lower()
    return n.endswith((".jpg", ".jpeg", ".png", ".webp", ".tif", ".tiff"))

def ingest_pdf_path(path: str, label: str):
    try:
        with open(path, "rb") as f:
            reader = PdfReader(f)
            for i, page in enumerate(reader.pages):
                try:
                    txt = page.extract_text() or ""
                except Exception:
                    txt = ""
                add_to_corpus(txt, source=f"PDF:{os.path.basename(label)}", page=i+1)
        return True
    except Exception as e:
        st.warning(f"PDF nelze naÄÃ­st ({path}): {e}")
        return False

def ingest_zip_path(path: str, label: str):
    try:
        with zipfile.ZipFile(path, "r") as z:
            names = [n for n in z.namelist() if is_image_name(n)]
            if not names:
                st.info(f"V ZIPu {label} nejsou obrÃ¡zky.")
                return True
            for n in names:
                with z.open(n) as f:
                    img = Image.open(io.BytesIO(f.read())).convert("RGB")
                    txt = pytesseract.image_to_string(img, lang="ces")
                    add_to_corpus(txt, source=f"ZIP:{label}/{n}", page=None)
        return True
    except Exception as e:
        st.warning(f"ZIP nelze naÄÃ­st ({path}): {e}")
        return False

def load_assets_once():
    if st.session_state.assets_loaded:
        return
    loaded_any = False
    if os.path.isdir(ASSETS_DIR):
        # NaÄti vÅ¡echna PDF
        for name in os.listdir(ASSETS_DIR):
            p = os.path.join(ASSETS_DIR, name)
            if name.lower().endswith(".pdf"):
                ok = ingest_pdf_path(p, name)
                loaded_any = loaded_any or ok
            elif name.lower().endswith(".zip"):
                ok = ingest_zip_path(p, name)
                loaded_any = loaded_any or ok
    if loaded_any:
        build_or_update_index()
        st.session_state.assets_loaded = True

# ========== POÄŒASÃ (wttr.in bez klÃ­Äe) ==========
def get_weather(city: str = DEFAULT_CITY) -> dict:
    import urllib.parse
    city_encoded = urllib.parse.quote(city)
    url = f"https://wttr.in/{city_encoded}?format=j1"
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()

        current = data["current_condition"][0]
        temp = float(current.get("temp_C", 0))
        desc = current["weatherDesc"][0]["value"]
        wind = float(current.get("windspeedKmph", 0))
        precip = float(current.get("precipMM", 0))

        return {"city": city, "temp": temp, "desc": desc, "wind": wind, "precip": precip > 0, "raw": data}
    except Exception:
        return {"city": city, "temp": 10, "desc": "nelze zjistit (offline data)", "wind": 0, "precip": False, "raw": {}}

def weather_context(w: Dict[str, Any]) -> str:
    wind_ms = w["wind"] / 3.6 if isinstance(w["wind"], (int, float)) else 0.0
    cold = (w["temp"] is not None) and (w["temp"] <= 5)
    windy = wind_ms >= 8.0  # ~28.8 km/h
    wet = bool(w["precip"])
    return "indoor" if cold or windy or wet else "outdoor"

# ========== DETERMINISTICKÃ PLÃNOVAÄŒ ==========
def periodization(sessions_per_week: int, age: str) -> Dict[str, Any]:
    # jednoduchÃ© meta: intenzita dle vÄ›ku + poÄtu jednotek
    base_int = "stÅ™ednÃ­"
    if sessions_per_week <= 2:
        base_int = "nÃ­zkÃ¡"
    elif sessions_per_week >= 4:
        base_int = "stÅ™ednÄ›-vysokÃ¡"
    return {"sessions_per_week": sessions_per_week, "base_intensity": base_int, "age": age}

def generate_plan(age_group: str, context: str, pz: Dict[str, Any], races: List[Dict[str, Any]]) -> Dict[str, Any]:
    # objemovÃ© body dle vÄ›ku
    base_points_map = {"U14 (do 13)": 40, "U16 (do 15)": 55}
    base_points = base_points_map.get(age_group, 45)

    # uprava dle poÄtu jednotek v tÃ½dnu (orientaÄnÄ›)
    spw = pz["sessions_per_week"]
    if spw <= 2:
        base_points = int(base_points * 0.8)
    elif spw >= 4:
        base_points = int(base_points * 1.1)

    warmup = [{"name": "bÄ›Å¾eckÃ¡ abeceda", "duration": "8â€“10 min"},
              {"name": "mobilita kotnÃ­k/kyÄle", "duration": "6 min"}]
    if context == "indoor":
        main = [{"name": "6Ã—50â€“60 m technickÃ½ sprint 85â€“90 %", "rest": "90 s"},
                {"name": "koordinaÄnÃ­ Å¾ebÅ™Ã­k", "duration": "8 min"}]
    else:
        main = [{"name": "6Ã—80 m rovinky (80â€“90 %) s meziklusem", "rest": "120 s"},
                {"name": "Å¡taf. pÅ™edÃ¡vky 4Ã—50 m (technika)", "rest": "plnÃ¡"}]

    strength = [{"name": "core okruh (plank, hollow, side) 2Ã—", "duration": "10 min"}]
    cooldown = [{"name": "vyklus + streÄink", "duration": "8 min"}]

    return {
        "goal": "rychlost + technika sprintu",
        "intensity": pz["base_intensity"],
        "volume_points": base_points,
        "context": context,
        "sessions_per_week": spw,
        "blocks": [
            {"part": "Warm-up", "items": warmup},
            {"part": "Main", "items": main},
            {"part": "Strength", "items": strength},
            {"part": "Cool-down", "items": cooldown},
        ],
        "safety": [
            "NepÅ™etÄ›Å¾ovat nad 90 % u 11â€“15 let.",
            "PlnÃ¡ regenerace mezi opakovÃ¡nÃ­mi.",
            "V chladnu prodlouÅ¾it rozcviÄenÃ­."
        ],
        "races_hint": races[:3] if races else []
    }

# ========== PROMPTY ==========
SYS_RAG = """Jsi asistent trenÃ©ra atletiky pro dÄ›ti 11â€“15 let. OdpovÃ­dej struÄnÄ›, Äesky.
VychÃ¡zej primÃ¡rnÄ› z poskytnutÃ½ch vÃ½ÅˆatkÅ¯ (CONTEXT). KdyÅ¾ si nejsi jistÃ½, Å™ekni to.
Dbej na bezpeÄnost, techniku a vÄ›kovÃ¡ omezenÃ­. PÅ™ipojuj struÄnÃ© reference (zdroj+strana/soubor)."""

USR_RAG = """DOTAZ: {q}
CONTEXT:
{ctx}
POKYN: OdpovÄ›z vÃ½hradnÄ› na zÃ¡kladÄ› CONTEXTU. Pokud nÄ›co nenÃ­ ve zdrojÃ­ch, Å™ekni to.
"""

SYS_PLAN = """Jsi trenÃ©r, kterÃ½ pÅ™etavÃ­ strukturovanÃ½ plÃ¡n (JSON) do ÄitelnÃ©ho trÃ©ninku pro dÄ›ti 11â€“15 let.
DodrÅ¾ intenzitu a objem. NabÃ­dni 1 indoor/outdoor alternativu, pokud kontext nedÃ¡vÃ¡ smysl.
Nakonec pÅ™idej krÃ¡tkÃ© 'ProÄ takto' a 'BezpeÄnost'. PiÅ¡ Äesky a struÄnÄ›."""

USR_PLAN = """ZÃKLAD:
{base}

METADATA:
- VÄ›k: {age}
- MÄ›sto/poÄasÃ­: {city_desc}
- PoÄet trÃ©ninkÅ¯ v tÃ½dnu: {spw}

POKYN:
SepiÅ¡ 1 trÃ©ninkovou jednotku (rozcviÄenÃ­ â†’ hlavnÃ­ ÄÃ¡st â†’ doplÅˆky â†’ cool-down),
zachovej nÃ¡zvy a parametry. PÅ™idej 1 alternativu (indoor/outdoor).
"""

# ========== LEVÃ PANEL â€“ INFO O ZDROJÃCH ==========
st.sidebar.header("ğŸ“š Zdroje")
st.sidebar.success("Zdroje jsou **pÅ™ednaÄtenÃ©** ze sloÅ¾ky `assets/` (PDF/ZIP).")
if st.sidebar.button("ğŸ” Znovu vybuildit index"):
    st.session_state.assets_loaded = False
    load_assets_once()
    st.sidebar.success("Index pÅ™ipraven âœ…")

# ========== PRAVÃ PANEL â€“ NASTAVENÃ ==========
st.sidebar.header("âš™ï¸ NastavenÃ­ plÃ¡nu")
age_group = st.sidebar.selectbox("VÄ›k/skupina", ["U14 (do 13)", "U16 (do 15)"], index=0)
sessions_per_week = st.sidebar.number_input("PoÄet trÃ©ninkÅ¯ v tÃ½dnu", min_value=1, max_value=7, value=3)
city = st.sidebar.text_input("MÄ›sto (poÄasÃ­)", value=DEFAULT_CITY)

# KalendÃ¡Å™ zÃ¡vodÅ¯ â€“ DOCX upload (volitelnÄ›)
import docx
def parse_races_docx(file_obj) -> List[Dict[str, Any]]:
    """ÄŒekÃ¡ Å™Ã¡dky typu: 2025-11-22: 60m, dÃ¡lka"""
    races = []
    try:
        doc = docx.Document(file_obj)
        for p in doc.paragraphs:
            line = p.text.strip()
            if not line:
                continue
            if ":" in line:
                date_str, rest = line.split(":", 1)
                date_str = date_str.strip()
                discs = [d.strip() for d in rest.split(",") if d.strip()]
                races.append({"date": date_str, "disciplines": discs})
    except Exception:
        pass
    return races

st.sidebar.markdown("**KalendÃ¡Å™ zÃ¡vodÅ¯ (volitelnÃ©, DOCX)** â€“ kaÅ¾dÃ½ Å™Ã¡dek `YYYY-MM-DD: 60m, dÃ¡lka`")
races_docx = st.sidebar.file_uploader("NahrÃ¡t DOCX", type=["docx"])
if races_docx:
    races = parse_races_docx(races_docx)
else:
    races = [{"date": "2025-11-22", "disciplines": ["60m", "dÃ¡lka"]}]

# ========== HLAVNÃ â€“ CHAT a PLÃN ==========
# NaÄti assets a index jednou
load_assets_once()

col1, col2 = st.columns([2,1])

with col1:
    st.subheader("ğŸ’¬ Chat nad tvÃ½mi (pÅ™ednaÄtenÃ½mi) zdroji")
    q = st.text_input("Zeptej se na cokoliv z metodikyâ€¦", placeholder="NapÅ™. Jak progresovat sprinty u U14 v zimÄ›?")
    if st.button("Odeslat dotaz") and q.strip():
        if st.session_state.index is None:
            st.warning("Zdroje nejsou naÄtenÃ© â€“ klikni na 'Znovu vybuildit index'.")
        else:
            topk = search_similar(q, k=6)
            ctx_blocks = []
            for d in topk:
                meta = d["meta"]
                ref = f'{meta["source"]}{f" s.{meta["page"]}" if meta["page"] else ""}'
                ctx_blocks.append(f"[{ref}] {d['text'][:800]}")
            prompt = USR_RAG.format(q=q, ctx="\n\n".join(ctx_blocks))
            client = st.session_state.openai_client
            resp = client.chat.completions.create(
                model=MODEL_CHAT,
                messages=[{"role":"system","content":SYS_RAG},
                          {"role":"user","content":prompt}],
                temperature=0.2,
            )
            st.markdown(resp.choices[0].message.content)

with col2:
    st.subheader("ğŸŒ¦ï¸ PoÄasÃ­ & plÃ¡n")
    # poÄasÃ­
    w = get_weather(city)
    st.metric("Teplota", f"{w['temp']} Â°C")
    wind_ms = w['wind']/3.6 if isinstance(w['wind'], (int,float)) else 0.0
    st.caption(f"{w['city']}: {w['desc']} | vÃ­tr {wind_ms:.1f} m/s")
    st.markdown("[ğŸŒ¦ Zobrazit radar na pocasiaradar.cz](https://www.pocasiaradar.cz/)")
    ctx = weather_context(w)

    # periodizace a plÃ¡n
    pz = periodization(sessions_per_week, age_group)
    base_plan = generate_plan(age_group, ctx, pz, races)

    st.json(base_plan, expanded=False)

    if st.button("ğŸ§  Vygenerovat Äitelnou verzi"):
        client = st.session_state.openai_client
        city_desc = f"{w['city']}: {w['desc']} ({w['temp']} Â°C)"
        prompt = USR_PLAN.format(
            base=json.dumps(base_plan, ensure_ascii=False, indent=2),
            age=age_group,
            city_desc=city_desc,
            spw=pz["sessions_per_week"],
        )
        resp = client.chat.completions.create(
            model=MODEL_CHAT,
            messages=[{"role":"system","content":SYS_PLAN},
                      {"role":"user","content":prompt}],
            temperature=0.3,
        )
        st.markdown(resp.choices[0].message.content)

    st.download_button(
        "â¬‡ï¸ StÃ¡hnout plÃ¡n (JSON)",
        data=json.dumps(base_plan, ensure_ascii=False, indent=2),
        file_name=f"plan_{date.today().isoformat()}.json",
        mime="application/json"
    )
